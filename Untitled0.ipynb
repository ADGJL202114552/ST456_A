{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPEoGbbBHa8I",
        "outputId": "64aeea4b-85ae-4595-c65b-61555ed0d8f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensorflow/Keras: 2.8.0\n"
          ]
        }
      ],
      "source": [
        "# Tensorflow / Keras\n",
        "from tensorflow import keras # for building Neural Networks\n",
        "print('Tensorflow/Keras: %s' % keras.__version__) # print version\n",
        "from keras.models import Sequential # for creating a linear stack of layers for our Neural Network\n",
        "from keras import Input, Model # for instantiating a keras tensor\n",
        "from keras.layers import Dense, Concatenate,Lambda # for creating regular densely-connected NN layers.\n",
        "from pandas import read_csv\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.backend import sum\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "P1"
      ],
      "metadata": {
        "id": "_JwPCU7Lh8Fg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data processing"
      ],
      "metadata": {
        "id": "EZkrkjFoHdNt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the dataset\n",
        "train_path = '/content/train-1.csv'\n",
        "train = read_csv(train_path, header=None)\n",
        "# split the dataset into input features (X) and class labels/targets (y)\n",
        "X_train, y_train = train.values[:, :-1], train.values[:, -1]\n",
        "# ensure all data are floating point values\n",
        "X_train = X_train.astype('float32')\n",
        "y_train = y_train.astype('float32')\n",
        "print(X_train.shape, y_train.shape)\n",
        "\n",
        "test_path = '/content/test-1.csv'\n",
        "test = read_csv(test_path, header=None)\n",
        "# split the dataset into input features (X) and class labels/targets (y)\n",
        "X_test, y_test = test.values[:, :-1], test.values[:, -1]\n",
        "# ensure all data are floating point values\n",
        "X_test = X_test.astype('float32')\n",
        "y_test = y_test.astype('float32')\n",
        "print(X_test.shape, y_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alru6WOLOaKf",
        "outputId": "e94e94c8-e5c7-450d-de4b-71126fce703b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100000, 10) (100000,)\n",
            "(10000, 10) (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "P1.1 Neural network"
      ],
      "metadata": {
        "id": "Jnwr_krMWGXN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_features = X_train.shape[1]\n",
        "\n",
        "lat_dim = 8\n",
        "\n",
        "## Model phi\n",
        "## A feedforward neural network with one hidden layer with 100 neurons and ReLU activation function, and the output layer with lat_dim output units.\n",
        "phi_model = Sequential()\n",
        "# Input and hidden layer\n",
        "phi_model.add(Dense(100, activation='relu', kernel_initializer='he_normal', input_shape=(n_features,)))\n",
        "# Output layer\n",
        "phi_model.add(Dense(lat_dim, activation='relu'))\n",
        "opt = SGD(learning_rate=0.0001)\n",
        "phi_model.compile(optimizer=opt, loss='mse', metrics='accuracy')\n",
        "\n",
        "## Sum up the phi\n",
        "phi_model2 = Sequential()\n",
        "phi_model2.add(phi_model)\n",
        "phi_model2.add(Lambda(lambda x: sum(x, axis=1,keepdims=True)))\n",
        "phi_model2.layers[0].trainable = False\n",
        "phi_model2.compile(optimizer=opt, loss='mse', metrics='accuracy')\n",
        "\n",
        "\n",
        "\n",
        "## Model rho\n",
        "## A feedforward neural network with one hidden layer with 100 neurons and ReLU activation function, and the input layer with 1 input unit.\n",
        "rho_model = Sequential()\n",
        "# Input layer where input unit is phi_model2 results\n",
        "rho_model.add(phi_model2)\n",
        "# Hidden layer\n",
        "rho_model.add(Dense(100, activation='relu', kernel_initializer='he_normal', input_shape=(1,)))\n",
        "# Output layer\n",
        "rho_model.add(Dense(1, activation='relu'))\n",
        "rho_model.compile(optimizer=opt, loss='mse', metrics='accuracy')\n",
        "\n",
        "phi_model.summary()\n",
        "phi_model2.summary()\n",
        "rho_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-uAl7PjHcH9",
        "outputId": "948a0313-db8b-47ef-f2e9-aaf166d90496"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 100)               1100      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 8)                 808       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,908\n",
            "Trainable params: 0\n",
            "Non-trainable params: 1,908\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " sequential (Sequential)     (None, 8)                 1908      \n",
            "                                                                 \n",
            " lambda (Lambda)             (None, 1)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,908\n",
            "Trainable params: 0\n",
            "Non-trainable params: 1,908\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " sequential_1 (Sequential)   (None, 1)                 1908      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 100)               200       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,209\n",
            "Trainable params: 301\n",
            "Non-trainable params: 1,908\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "P1.2 Train the neural network "
      ],
      "metadata": {
        "id": "BSCb5Z4sXQ8R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validation dataset "
      ],
      "metadata": {
        "id": "j6KzEsS3Vtu-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# split the dataset into input features (X) and class labels/targets (y)\n",
        "X, y = train.values[:, :-1], train.values[:, -1]\n",
        "# ensure all data are floating point values\n",
        "X = X.astype('float32')\n",
        "# encode strings to integer\n",
        "y = LabelEncoder().fit_transform(y)\n",
        "# split into training (90%) and validation (10%) samples\n",
        "X_tra, X_val, y_tra, y_val = train_test_split(X, y, test_size=0.10)\n",
        "print(X_tra.shape, X_val.shape, y_tra.shape, y_val.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2FMJ9UtVsnq",
        "outputId": "c64adcb0-42ee-4295-d83a-17db4d65b6f8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(90000, 10) (10000, 10) (90000,) (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. lat_dim = 5 "
      ],
      "metadata": {
        "id": "1Xy3OgJeVnNW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lat_dim = 5\n",
        "\n",
        "## Model phi\n",
        "## A feedforward neural network with one hidden layer with 100 neurons and ReLU activation function, and the output layer with lat_dim output units.\n",
        "phi_model = Sequential()\n",
        "# Input and hidden layer\n",
        "phi_model.add(Dense(100, activation='relu', kernel_initializer='he_normal', input_shape=(n_features,)))\n",
        "# Output layer\n",
        "phi_model.add(Dense(lat_dim, activation='relu'))\n",
        "opt = SGD(learning_rate=0.0001)\n",
        "phi_model.compile(optimizer=opt, loss='mse', metrics='accuracy')\n",
        "\n",
        "phi_model2 = Sequential()\n",
        "phi_model2.add(phi_model)\n",
        "phi_model2.add(Lambda(lambda x: sum(x, axis=1,keepdims=True)))\n",
        "phi_model2.layers[0].trainable = False\n",
        "phi_model2.compile(optimizer=opt, loss='mse', metrics='accuracy')\n",
        "\n",
        "\n",
        "\n",
        "## Model rho\n",
        "## A feedforward neural network with one hidden layer with 100 neurons and ReLU activation function, and the input layer with 1 input unit.\n",
        "rho_model = Sequential()\n",
        "# Input layer where input units equal to 1 and hidden layer\n",
        "rho_model.add(phi_model2)\n",
        "rho_model.add(Dense(100, activation='relu', kernel_initializer='he_normal', input_shape=(1,)))\n",
        "# Output layer\n",
        "rho_model.add(Dense(1, activation='relu'))\n",
        "rho_model.compile(optimizer=opt, loss='mse', metrics='accuracy')\n",
        "\n",
        "\n",
        "# fit the model\n",
        "rho_model.fit(X_test, y_test, epochs=10, batch_size=128,validation_data=(X_val, y_val))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbYV041fXV25",
        "outputId": "0bb7d0d1-11fe-4752-fc45-a0ef9da8e876"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "79/79 [==============================] - 1s 10ms/step - loss: 0.1371 - accuracy: 0.0000e+00 - val_loss: 3305953280.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.1064 - accuracy: 0.0000e+00 - val_loss: 3305947392.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0949 - accuracy: 0.0000e+00 - val_loss: 3305945088.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.0901 - accuracy: 0.0000e+00 - val_loss: 3305943040.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0876 - accuracy: 0.0000e+00 - val_loss: 3305941760.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0860 - accuracy: 0.0000e+00 - val_loss: 3305940480.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.0847 - accuracy: 0.0000e+00 - val_loss: 3305939968.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0835 - accuracy: 0.0000e+00 - val_loss: 3305939200.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0823 - accuracy: 0.0000e+00 - val_loss: 3305939200.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0812 - accuracy: 0.0000e+00 - val_loss: 3305939200.0000 - val_accuracy: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc69d66d590>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the model\n",
        "mse, mae = rho_model.evaluate(X_test, y_test, verbose=0)\n",
        "print('MSE: %.3f, MAE: %.3f' % (mse,  mae))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRnBOs0OBjON",
        "outputId": "3ed324d0-da88-4089-9aa1-1d7691c52cb8"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 0.081, MAE: 0.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. lat_dim =100"
      ],
      "metadata": {
        "id": "8Ive532dJMg7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lat_dim = 100\n",
        "## Model phi\n",
        "## A feedforward neural network with one hidden layer with 100 neurons and ReLU activation function, and the output layer with lat_dim output units.\n",
        "phi_model = Sequential()\n",
        "# Input and hidden layer\n",
        "phi_model.add(Dense(100, activation='relu', kernel_initializer='he_normal', input_shape=(n_features,)))\n",
        "# Output layer\n",
        "phi_model.add(Dense(lat_dim, activation='relu'))\n",
        "opt = SGD(learning_rate=0.0001)\n",
        "phi_model.compile(optimizer=opt, loss='mse', metrics='accuracy')\n",
        "\n",
        "phi_model2 = Sequential()\n",
        "phi_model2.add(phi_model)\n",
        "phi_model2.add(Lambda(lambda x: sum(x, axis=1,keepdims=True)))\n",
        "phi_model2.layers[0].trainable = False\n",
        "phi_model2.compile(optimizer=opt, loss='mse', metrics='accuracy')\n",
        "\n",
        "## Model rho\n",
        "## A feedforward neural network with one hidden layer with 100 neurons and ReLU activation function, and the input layer with 1 input unit.\n",
        "rho_model = Sequential()\n",
        "# Input layer where input units equal to 1 and hidden layer\n",
        "rho_model.add(phi_model2)\n",
        "rho_model.add(Dense(100, activation='relu', kernel_initializer='he_normal', input_shape=(1,)))\n",
        "# Output layer\n",
        "rho_model.add(Dense(1, activation='relu'))\n",
        "rho_model.compile(optimizer=opt, loss='mse', metrics='accuracy')\n",
        "\n",
        "rho_model.fit(X_test, y_test, epochs=10, batch_size=128,validation_data=(X_val, y_val))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLhBuMQfYQwo",
        "outputId": "c50aab2b-6c52-4fe8-a2a7-7d04351e497c"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "79/79 [==============================] - 1s 6ms/step - loss: 1.1459 - accuracy: 0.0000e+00 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.2701 - accuracy: 0.0000e+00 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.2701 - accuracy: 0.0000e+00 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.2701 - accuracy: 0.0000e+00 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.2701 - accuracy: 0.0000e+00 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.2701 - accuracy: 0.0000e+00 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.2701 - accuracy: 0.0000e+00 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.2701 - accuracy: 0.0000e+00 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.2701 - accuracy: 0.0000e+00 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.2701 - accuracy: 0.0000e+00 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc69d7f9450>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mse, mae = rho_model.evaluate(X_test, y_test, verbose=0)\n",
        "print('MSE: %.3f, MAE: %.3f' % (mse,  mae))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_JQ3MgQc1mI",
        "outputId": "6facb3ec-e906-458f-cb7b-284ad0f3ce74"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 0.270, MAE: 0.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When we use larger lat_dim, the MSE is lower. When lat_dim is 100, the MSE is lower than it when lat_lim is 5."
      ],
      "metadata": {
        "id": "kEIqF8uUJG2Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "P1.3 "
      ],
      "metadata": {
        "id": "M8u5YufCc67n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "learning rates = 0.01"
      ],
      "metadata": {
        "id": "7xuYaVlSdBq9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lat_dim = 100\n",
        "## Model phi\n",
        "## A feedforward neural network with one hidden layer with 100 neurons and ReLU activation function, and the output layer with lat_dim output units.\n",
        "phi_model = Sequential()\n",
        "# Input and hidden layer\n",
        "phi_model.add(Dense(100, activation='relu', kernel_initializer='he_normal', input_shape=(n_features,)))\n",
        "# Output layer\n",
        "phi_model.add(Dense(lat_dim, activation='relu'))\n",
        "opt = SGD(learning_rate=0.01)\n",
        "phi_model.compile(optimizer=opt, loss='mse', metrics='accuracy')\n",
        "\n",
        "phi_model2 = Sequential()\n",
        "phi_model2.add(phi_model)\n",
        "phi_model2.add(Lambda(lambda x: sum(x, axis=1,keepdims=True)))\n",
        "phi_model2.layers[0].trainable = False\n",
        "phi_model2.compile(optimizer=opt, loss='mse', metrics='accuracy')\n",
        "\n",
        "## Model rho\n",
        "## A feedforward neural network with one hidden layer with 100 neurons and ReLU activation function, and the input layer with 1 input unit.\n",
        "rho_model = Sequential()\n",
        "# Input layer where input units equal to 1 and hidden layer\n",
        "rho_model.add(phi_model2)\n",
        "rho_model.add(Dense(100, activation='relu', kernel_initializer='he_normal', input_shape=(1,)))\n",
        "# Output layer\n",
        "rho_model.add(Dense(1, activation='relu'))\n",
        "rho_model.compile(optimizer=opt, loss='mse', metrics='accuracy')\n",
        "\n",
        "rho_model.fit(X_test, y_test, epochs=10, batch_size=128,validation_data=(X_val, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSDu-gjEdL_u",
        "outputId": "4a6ce8ec-2fd1-4a5f-b03a-acb5d26cb61e"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "79/79 [==============================] - 1s 6ms/step - loss: 0.2701 - accuracy: 0.0000e+00 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.2701 - accuracy: 0.0000e+00 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.2701 - accuracy: 0.0000e+00 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.2701 - accuracy: 0.0000e+00 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.2701 - accuracy: 0.0000e+00 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.2701 - accuracy: 0.0000e+00 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.2701 - accuracy: 0.0000e+00 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.2701 - accuracy: 0.0000e+00 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.2701 - accuracy: 0.0000e+00 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.2701 - accuracy: 0.0000e+00 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc690751ed0>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "learning rates = 0.1"
      ],
      "metadata": {
        "id": "NbmLwaSldIE0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lat_dim = 100\n",
        "## Model phi\n",
        "## A feedforward neural network with one hidden layer with 100 neurons and ReLU activation function, and the output layer with lat_dim output units.\n",
        "phi_model = Sequential()\n",
        "# Input and hidden layer\n",
        "phi_model.add(Dense(100, activation='relu', kernel_initializer='he_normal', input_shape=(n_features,)))\n",
        "# Output layer\n",
        "phi_model.add(Dense(lat_dim, activation='relu'))\n",
        "opt = SGD(learning_rate=0.1)\n",
        "phi_model.compile(optimizer=opt, loss='mse', metrics='accuracy')\n",
        "\n",
        "phi_model2 = Sequential()\n",
        "phi_model2.add(phi_model)\n",
        "phi_model2.add(Lambda(lambda x: sum(x, axis=1,keepdims=True)))\n",
        "phi_model2.layers[0].trainable = False\n",
        "phi_model2.compile(optimizer=opt, loss='mse', metrics='accuracy')\n",
        "\n",
        "## Model rho\n",
        "## A feedforward neural network with one hidden layer with 100 neurons and ReLU activation function, and the input layer with 1 input unit.\n",
        "rho_model = Sequential()\n",
        "# Input layer where input units equal to 1 and hidden layer\n",
        "rho_model.add(phi_model2)\n",
        "rho_model.add(Dense(100, activation='relu', kernel_initializer='he_normal', input_shape=(1,)))\n",
        "# Output layer\n",
        "rho_model.add(Dense(1, activation='relu'))\n",
        "rho_model.compile(optimizer=opt, loss='mse', metrics='accuracy')\n",
        "\n",
        "rho_model.fit(X_test, y_test, epochs=10, batch_size=128,validation_data=(X_val, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4653c99a-4b3e-4a2c-fb44-db7491f23e7a",
        "id": "-kqxvm5bdVWW"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function WeakKeyDictionary.__init__.<locals>.remove at 0x7fc6a568a950>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/weakref.py\", line 358, in remove\n",
            "    def remove(k, selfref=ref(self)):\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 1s 6ms/step - loss: 9.9871 - accuracy: 0.0000e+00 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.2701 - accuracy: 0.0000e+00 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.2701 - accuracy: 0.0000e+00 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.2701 - accuracy: 0.0000e+00 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.2701 - accuracy: 0.0000e+00 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.2701 - accuracy: 0.0000e+00 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.2701 - accuracy: 0.0000e+00 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.2701 - accuracy: 0.0000e+00 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.2701 - accuracy: 0.0000e+00 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.2701 - accuracy: 0.0000e+00 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc68dfe3110>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "learning rates = 0.5"
      ],
      "metadata": {
        "id": "6AeIsQO8dIPc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lat_dim = 100\n",
        "## Model phi\n",
        "## A feedforward neural network with one hidden layer with 100 neurons and ReLU activation function, and the output layer with lat_dim output units.\n",
        "phi_model = Sequential()\n",
        "# Input and hidden layer\n",
        "phi_model.add(Dense(100, activation='relu', kernel_initializer='he_normal', input_shape=(n_features,)))\n",
        "# Output layer\n",
        "phi_model.add(Dense(lat_dim, activation='relu'))\n",
        "opt = SGD(learning_rate=0.5)\n",
        "phi_model.compile(optimizer=opt, loss='mse', metrics='accuracy')\n",
        "\n",
        "phi_model2 = Sequential()\n",
        "phi_model2.add(phi_model)\n",
        "phi_model2.add(Lambda(lambda x: sum(x, axis=1,keepdims=True)))\n",
        "phi_model2.layers[0].trainable = False\n",
        "phi_model2.compile(optimizer=opt, loss='mse', metrics='accuracy')\n",
        "\n",
        "## Model rho\n",
        "## A feedforward neural network with one hidden layer with 100 neurons and ReLU activation function, and the input layer with 1 input unit.\n",
        "rho_model = Sequential()\n",
        "# Input layer where input units equal to 1 and hidden layer\n",
        "rho_model.add(phi_model2)\n",
        "rho_model.add(Dense(100, activation='relu', kernel_initializer='he_normal', input_shape=(1,)))\n",
        "# Output layer\n",
        "rho_model.add(Dense(1, activation='relu'))\n",
        "rho_model.compile(optimizer=opt, loss='mse', metrics='accuracy')\n",
        "\n",
        "rho_model.fit(X_test, y_test, epochs=10, batch_size=128,validation_data=(X_val, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c54fbaae-59ac-459e-cb9c-b48b6fa718ff",
        "id": "M0M3VkgddYFM"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 0.2701 - accuracy: 0.0000e+00 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.2701 - accuracy: 0.0000e+00 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "79/79 [==============================] - 1s 15ms/step - loss: 0.2701 - accuracy: 0.0000e+00 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.2701 - accuracy: 0.0000e+00 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "79/79 [==============================] - 1s 13ms/step - loss: 0.2701 - accuracy: 0.0000e+00 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.2701 - accuracy: 0.0000e+00 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.2701 - accuracy: 0.0000e+00 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.2701 - accuracy: 0.0000e+00 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.2701 - accuracy: 0.0000e+00 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.2701 - accuracy: 0.0000e+00 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc69d879cd0>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model learns better with higher learning rate. "
      ],
      "metadata": {
        "id": "8P08uI_nJv7B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "P1.4"
      ],
      "metadata": {
        "id": "rdf1dBA0dc1O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lat_dim = 100\n",
        "## Model phi\n",
        "## A feedforward neural network with one hidden layer with 100 neurons and ReLU activation function, and the output layer with lat_dim output units.\n",
        "phi_model = Sequential()\n",
        "# Input and hidden layer\n",
        "phi_model.add(Dense(100, activation='relu', kernel_initializer='he_normal', input_shape=(n_features,)))\n",
        "# Output layer\n",
        "phi_model.add(Dense(lat_dim, activation='relu'))\n",
        "opt = SGD(learning_rate=0.01)\n",
        "phi_model.compile(optimizer=opt, loss='mse', metrics='accuracy')\n",
        "\n",
        "phi_model2 = Sequential()\n",
        "phi_model2.add(phi_model)\n",
        "phi_model2.add(Lambda(lambda x: sum(x, axis=1,keepdims=True)))\n",
        "phi_model2.layers[0].trainable = False\n",
        "phi_model2.compile(optimizer=opt, loss='mse', metrics='accuracy')\n",
        "\n",
        "## Model rho\n",
        "## A feedforward neural network with one hidden layer with 100 neurons and ReLU activation function, and the input layer with 1 input unit.\n",
        "rho_model = Sequential()\n",
        "# Input layer where input units equal to 1 and hidden layer\n",
        "rho_model.add(phi_model2)\n",
        "rho_model.add(Dense(100, activation='relu', kernel_initializer='he_normal', input_shape=(1,)))\n",
        "# Output layer\n",
        "rho_model.add(Dense(1, activation='relu'))\n",
        "rho_model.compile(optimizer=opt, loss='mse', metrics='accuracy')\n",
        "\n",
        "rho_model.fit(X_tra, y_tra, epochs=50, batch_size=128,validation_data=(X_val, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b0c159c-b571-45ac-986c-f4effc95a76c",
        "id": "DiJqkNLCe4E-"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "704/704 [==============================] - 2s 3ms/step - loss: 3336316928.0000 - accuracy: 1.1111e-05 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336318208.0000 - accuracy: 1.1111e-05 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336316928.0000 - accuracy: 1.1111e-05 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336318720.0000 - accuracy: 1.1111e-05 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336317440.0000 - accuracy: 1.1111e-05 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336316416.0000 - accuracy: 1.1111e-05 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336317952.0000 - accuracy: 1.1111e-05 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336316160.0000 - accuracy: 1.1111e-05 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "704/704 [==============================] - 2s 3ms/step - loss: 3336316160.0000 - accuracy: 1.1111e-05 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336317440.0000 - accuracy: 1.1111e-05 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336316416.0000 - accuracy: 1.1111e-05 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336316160.0000 - accuracy: 1.1111e-05 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336318976.0000 - accuracy: 1.1111e-05 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336316928.0000 - accuracy: 1.1111e-05 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336318720.0000 - accuracy: 1.1111e-05 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336317952.0000 - accuracy: 1.1111e-05 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336316416.0000 - accuracy: 1.1111e-05 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336319744.0000 - accuracy: 1.1111e-05 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "704/704 [==============================] - 2s 3ms/step - loss: 3336317440.0000 - accuracy: 1.1111e-05 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336317440.0000 - accuracy: 1.1111e-05 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336317952.0000 - accuracy: 1.1111e-05 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "704/704 [==============================] - 2s 3ms/step - loss: 3336318208.0000 - accuracy: 1.1111e-05 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336318720.0000 - accuracy: 1.1111e-05 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "704/704 [==============================] - 2s 3ms/step - loss: 3336318976.0000 - accuracy: 1.1111e-05 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "704/704 [==============================] - 2s 3ms/step - loss: 3336317440.0000 - accuracy: 1.1111e-05 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "704/704 [==============================] - 2s 3ms/step - loss: 3336317440.0000 - accuracy: 1.1111e-05 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336318720.0000 - accuracy: 1.1111e-05 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336317184.0000 - accuracy: 1.1111e-05 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336314880.0000 - accuracy: 1.1111e-05 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336317440.0000 - accuracy: 1.1111e-05 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336317440.0000 - accuracy: 1.1111e-05 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336317440.0000 - accuracy: 1.1111e-05 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336317184.0000 - accuracy: 1.1111e-05 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336317440.0000 - accuracy: 1.1111e-05 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336315648.0000 - accuracy: 1.1111e-05 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336318208.0000 - accuracy: 1.1111e-05 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336316416.0000 - accuracy: 1.1111e-05 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "704/704 [==============================] - 1s 2ms/step - loss: 3336318208.0000 - accuracy: 1.1111e-05 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336320512.0000 - accuracy: 1.1111e-05 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336317184.0000 - accuracy: 1.1111e-05 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336317184.0000 - accuracy: 1.1111e-05 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336316416.0000 - accuracy: 1.1111e-05 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336317184.0000 - accuracy: 1.1111e-05 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336315392.0000 - accuracy: 1.1111e-05 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336315392.0000 - accuracy: 1.1111e-05 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336318976.0000 - accuracy: 1.1111e-05 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336317952.0000 - accuracy: 1.1111e-05 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336318208.0000 - accuracy: 1.1111e-05 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336317184.0000 - accuracy: 1.1111e-05 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336317184.0000 - accuracy: 1.1111e-05 - val_loss: 3305976064.0000 - val_accuracy: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc69c1e1f90>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lat_dim = 100\n",
        "## Model phi\n",
        "## A feedforward neural network with one hidden layer with 100 neurons and ReLU activation function, and the output layer with lat_dim output units.\n",
        "phi_model = Sequential()\n",
        "# Input and hidden layer\n",
        "phi_model.add(Dense(100, activation='sigmoid', kernel_initializer='he_normal', input_shape=(n_features,)))\n",
        "# Output layer\n",
        "phi_model.add(Dense(lat_dim, activation='sigmoid'))\n",
        "opt = SGD(learning_rate=0.01)\n",
        "phi_model.compile(optimizer=opt, loss='mse', metrics='accuracy')\n",
        "\n",
        "phi_model2 = Sequential()\n",
        "phi_model2.add(phi_model)\n",
        "phi_model2.add(Lambda(lambda x: sum(x, axis=1,keepdims=True)))\n",
        "phi_model2.layers[0].trainable = False\n",
        "phi_model2.compile(optimizer=opt, loss='mse', metrics='accuracy')\n",
        "\n",
        "## Model rho\n",
        "## A feedforward neural network with one hidden layer with 100 neurons and ReLU activation function, and the input layer with 1 input unit.\n",
        "rho_model = Sequential()\n",
        "# Input layer where input units equal to 1 and hidden layer\n",
        "rho_model.add(phi_model2)\n",
        "rho_model.add(Dense(100, activation='sigmoid', kernel_initializer='he_normal', input_shape=(1,)))\n",
        "# Output layer\n",
        "rho_model.add(Dense(1, activation='sigmoid'))\n",
        "rho_model.compile(optimizer=opt, loss='mse', metrics='accuracy')\n",
        "\n",
        "rho_model.fit(X_tra, y_tra, epochs=50, batch_size=128,validation_data=(X_val, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "XSIfQORegr7D",
        "outputId": "22f56220-efd2-44cb-a473-97596d8243ce"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "149/704 [=====>........................] - ETA: 1s - loss: 3362196224.0000 - accuracy: 0.0000e+00"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-d8b6574ba700>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mrho_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mrho_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tra\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tra\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Relu activation function is faster than sigmoid."
      ],
      "metadata": {
        "id": "dOx0TwniOLWA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "P1.5"
      ],
      "metadata": {
        "id": "MdnO-3S1h0vK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lat_dim = [1,2,3,4,5,6,7,8,9,10,20,30,40,50,60,70,80,90,100]\n",
        "mse = []\n",
        "for i in lat_dim:\n",
        "  lat_dim = i\n",
        "  ## Model phi\n",
        "  ## A feedforward neural network with one hidden layer with 100 neurons and ReLU activation function, and the output layer with lat_dim output units.\n",
        "  phi_model = Sequential()\n",
        "  # Input and hidden layer\n",
        "  phi_model.add(Dense(100, activation='sigmoid', kernel_initializer='he_normal', input_shape=(n_features,)))\n",
        "  # Output layer\n",
        "  phi_model.add(Dense(lat_dim, activation='sigmoid'))\n",
        "  opt = SGD(learning_rate=0.01)\n",
        "  phi_model.compile(optimizer=opt, loss='mse', metrics='accuracy')\n",
        "\n",
        "  phi_model2 = Sequential()\n",
        "  phi_model2.add(phi_model)\n",
        "  phi_model2.add(Lambda(lambda x: sum(x, axis=1,keepdims=True)))\n",
        "  phi_model2.layers[0].trainable = False\n",
        "  phi_model2.compile(optimizer=opt, loss='mse', metrics='accuracy')\n",
        "\n",
        "  ## Model rho\n",
        "  ## A feedforward neural network with one hidden layer with 100 neurons and ReLU activation function, and the input layer with 1 input unit.\n",
        "  rho_model = Sequential()\n",
        "  # Input layer where input units equal to 1 and hidden layer\n",
        "  rho_model.add(phi_model2)\n",
        "  rho_model.add(Dense(100, activation='sigmoid', kernel_initializer='he_normal', input_shape=(1,)))\n",
        "  # Output layer\n",
        "  rho_model.add(Dense(1, activation='sigmoid'))\n",
        "  rho_model.compile(optimizer=opt, loss='mse', metrics='mse')\n",
        "  rho_model.compile(optimizer=opt, loss='mse', metrics='mse')\n",
        "  history = rho_model.fit(X_tra, y_tra, epochs=5, batch_size=128,validation_data=(X_val, y_val))\n",
        "  min_mse = min(history.history['mse'])\n",
        "  mse.append(min_mse)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjiidR7giADI",
        "outputId": "09cc3404-f821-4ef1-f347-2c9f7a7912cf"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "704/704 [==============================] - 5s 6ms/step - loss: 3336218112.0000 - mse: 3336218112.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 2/5\n",
            "704/704 [==============================] - 3s 4ms/step - loss: 3336219392.0000 - mse: 3336219392.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 3/5\n",
            "704/704 [==============================] - 3s 4ms/step - loss: 3336217600.0000 - mse: 3336217600.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 4/5\n",
            "704/704 [==============================] - 3s 5ms/step - loss: 3336216064.0000 - mse: 3336216064.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 5/5\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336217344.0000 - mse: 3336217344.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 1/5\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336219136.0000 - mse: 3336219136.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 2/5\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336216576.0000 - mse: 3336216576.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 3/5\n",
            "704/704 [==============================] - 1s 2ms/step - loss: 3336218368.0000 - mse: 3336218368.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 4/5\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336218368.0000 - mse: 3336218368.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 5/5\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336217344.0000 - mse: 3336217344.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 1/5\n",
            "704/704 [==============================] - 2s 3ms/step - loss: 3336217600.0000 - mse: 3336217600.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 2/5\n",
            "704/704 [==============================] - 1s 2ms/step - loss: 3336217600.0000 - mse: 3336217600.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 3/5\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336216832.0000 - mse: 3336216832.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 4/5\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336215296.0000 - mse: 3336215296.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 5/5\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336218112.0000 - mse: 3336218112.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 1/5\n",
            "704/704 [==============================] - 2s 3ms/step - loss: 3336216576.0000 - mse: 3336216576.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 2/5\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336218368.0000 - mse: 3336218368.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 3/5\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336217344.0000 - mse: 3336217344.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 4/5\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336219392.0000 - mse: 3336219392.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 5/5\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336219136.0000 - mse: 3336219136.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 1/5\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336214528.0000 - mse: 3336214528.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 2/5\n",
            "704/704 [==============================] - 1s 2ms/step - loss: 3336218112.0000 - mse: 3336218112.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 3/5\n",
            "704/704 [==============================] - 1s 2ms/step - loss: 3336215296.0000 - mse: 3336215296.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 4/5\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336216064.0000 - mse: 3336216064.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 5/5\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336216576.0000 - mse: 3336216576.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 1/5\n",
            "704/704 [==============================] - 2s 3ms/step - loss: 3336218368.0000 - mse: 3336218368.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 2/5\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336219136.0000 - mse: 3336219136.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 3/5\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336216832.0000 - mse: 3336216832.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 4/5\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336214272.0000 - mse: 3336214272.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 5/5\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336217344.0000 - mse: 3336217344.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 1/5\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336218112.0000 - mse: 3336218112.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 2/5\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336218368.0000 - mse: 3336218368.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 3/5\n",
            "704/704 [==============================] - 1s 2ms/step - loss: 3336216064.0000 - mse: 3336216064.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 4/5\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336215040.0000 - mse: 3336215040.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 5/5\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336219136.0000 - mse: 3336219136.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 1/5\n",
            "704/704 [==============================] - 2s 3ms/step - loss: 3336218368.0000 - mse: 3336218368.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 2/5\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336216576.0000 - mse: 3336216576.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 3/5\n",
            "704/704 [==============================] - 1s 2ms/step - loss: 3336218368.0000 - mse: 3336218368.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 4/5\n",
            "704/704 [==============================] - 1s 2ms/step - loss: 3336216064.0000 - mse: 3336216064.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 5/5\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336219136.0000 - mse: 3336219136.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 1/5\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336218368.0000 - mse: 3336218368.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 2/5\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336219392.0000 - mse: 3336219392.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 3/5\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336216576.0000 - mse: 3336216576.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 4/5\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336217344.0000 - mse: 3336217344.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 5/5\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336220672.0000 - mse: 3336220672.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 1/5\n",
            "704/704 [==============================] - 2s 3ms/step - loss: 3336216576.0000 - mse: 3336216576.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 2/5\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336216064.0000 - mse: 3336216064.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 3/5\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336215808.0000 - mse: 3336215808.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 4/5\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336217344.0000 - mse: 3336217344.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 5/5\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336216832.0000 - mse: 3336216832.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 1/5\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336217600.0000 - mse: 3336217600.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 2/5\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336217344.0000 - mse: 3336217344.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 3/5\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336217344.0000 - mse: 3336217344.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 4/5\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336218112.0000 - mse: 3336218112.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 5/5\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336216064.0000 - mse: 3336216064.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 1/5\n",
            "704/704 [==============================] - 3s 2ms/step - loss: 3336218112.0000 - mse: 3336218112.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 2/5\n",
            "704/704 [==============================] - 2s 3ms/step - loss: 3336215296.0000 - mse: 3336215296.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 3/5\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336216832.0000 - mse: 3336216832.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 4/5\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336216832.0000 - mse: 3336216832.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 5/5\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336217600.0000 - mse: 3336217600.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 1/5\n",
            "704/704 [==============================] - 3s 4ms/step - loss: 3336215808.0000 - mse: 3336215808.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 2/5\n",
            "704/704 [==============================] - 1s 2ms/step - loss: 3336215808.0000 - mse: 3336215808.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 3/5\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336218112.0000 - mse: 3336218112.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 4/5\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336215808.0000 - mse: 3336215808.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 5/5\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336215808.0000 - mse: 3336215808.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 1/5\n",
            "704/704 [==============================] - 2s 3ms/step - loss: 3336217600.0000 - mse: 3336217600.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 2/5\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336215040.0000 - mse: 3336215040.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 3/5\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336217600.0000 - mse: 3336217600.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 4/5\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336218368.0000 - mse: 3336218368.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 5/5\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336215040.0000 - mse: 3336215040.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 1/5\n",
            "704/704 [==============================] - 2s 3ms/step - loss: 3336217344.0000 - mse: 3336217344.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 2/5\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336218368.0000 - mse: 3336218368.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 3/5\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336217600.0000 - mse: 3336217600.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 4/5\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336215808.0000 - mse: 3336215808.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 5/5\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336215808.0000 - mse: 3336215808.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 1/5\n",
            "704/704 [==============================] - 2s 3ms/step - loss: 3336216832.0000 - mse: 3336216832.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 2/5\n",
            "704/704 [==============================] - 2s 3ms/step - loss: 3336218368.0000 - mse: 3336218368.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 3/5\n",
            "704/704 [==============================] - 2s 3ms/step - loss: 3336215808.0000 - mse: 3336215808.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 4/5\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336218624.0000 - mse: 3336218624.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 5/5\n",
            "704/704 [==============================] - 2s 3ms/step - loss: 3336216832.0000 - mse: 3336216832.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 1/5\n",
            "704/704 [==============================] - 2s 3ms/step - loss: 3336218112.0000 - mse: 3336218112.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 2/5\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336218624.0000 - mse: 3336218624.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 3/5\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336216832.0000 - mse: 3336216832.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 4/5\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336219392.0000 - mse: 3336219392.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 5/5\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336215296.0000 - mse: 3336215296.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 1/5\n",
            "704/704 [==============================] - 2s 3ms/step - loss: 3336218112.0000 - mse: 3336218112.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 2/5\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336217344.0000 - mse: 3336217344.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 3/5\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336217344.0000 - mse: 3336217344.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 4/5\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336218624.0000 - mse: 3336218624.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 5/5\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336218112.0000 - mse: 3336218112.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 1/5\n",
            "704/704 [==============================] - 2s 3ms/step - loss: 3336216576.0000 - mse: 3336216576.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 2/5\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336218624.0000 - mse: 3336218624.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 3/5\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336218112.0000 - mse: 3336218112.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 4/5\n",
            "704/704 [==============================] - 2s 2ms/step - loss: 3336217600.0000 - mse: 3336217600.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n",
            "Epoch 5/5\n",
            "704/704 [==============================] - 2s 3ms/step - loss: 3336218368.0000 - mse: 3336218368.0000 - val_loss: 3305877248.0000 - val_mse: 3305877248.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lat_dim = [1,2,3,4,5,6,7,8,9,10,20,30,40,50,60,70,80,90,100]\n",
        "plt.plot(lat_dim,mse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "r4FhVbYvIKZG",
        "outputId": "a1ea3af2-5fbf-4a00-e631-a6bc7a944efe"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fc690925e10>]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The MSE varies and reaches its peak when lat_dim is 90."
      ],
      "metadata": {
        "id": "89eaN4irQY_w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2"
      ],
      "metadata": {
        "id": "0vEKRZN_7DRv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "data processing "
      ],
      "metadata": {
        "id": "if7Xb32b7D-1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the dataset\n",
        "x2train_path = '/content/xtrain-2.csv'\n",
        "x2train = read_csv(x2train_path, header=None)\n",
        "y2train_path = '/content/ytrain-2.csv'\n",
        "y2train = read_csv(y2train_path, header=None)\n",
        "# split the dataset into input features (X) and class labels/targets (y)\n",
        "X2_train, y2_train = x2train.values[1:,1:], y2train.values[1:,1:]\n",
        "# ensure all data are floating point values\n",
        "X2_train = X2_train.astype('float32')\n",
        "y2_train = y2_train.astype('float32')\n",
        "print(X2_train.shape, y2_train.shape)\n",
        "\n",
        "x2test_path = '/content/xtest-2.csv'\n",
        "x2test = read_csv(x2test_path, header=None)\n",
        "y2test_path = '/content/ytest-2.csv'\n",
        "y2test = read_csv(y2test_path, header=None)\n",
        "# split the dataset into input features (X) and class labels/targets (y)\n",
        "X2_test, y2_test = x2test.values[1:,1:], y2test.values[1:,1:]\n",
        "# ensure all data are floating point values\n",
        "X2_test = X2_test.astype('float32')\n",
        "y2_test = y2_test.astype('float32')\n",
        "print(X2_test.shape, y2_test.shape)\n",
        "\n",
        "# split into training (90%) and validation (10%) samples\n",
        "X2_tra, X2_val, y2_tra, y2_val = x2train.values[1:180001,1:],x2train.values[180001:,1:],y2train.values[1:180001,1:],y2train.values[180001:,1:]\n",
        "print(X2_tra.shape, X2_val.shape, y2_tra.shape, y2_val.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v99MDPbN7HZD",
        "outputId": "51b0a5e9-ba6d-44b6-f8e7-ff2e4a54c2de"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(200000, 15) (200000, 5)\n",
            "(200000, 15) (200000, 5)\n",
            "(180000, 15) (20000, 15) (180000, 5) (20000, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define affine transformation"
      ],
      "metadata": {
        "id": "aImRaXoxBfND"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fL_1(X,A_l,B_l,c_l):\n",
        "  m = len(X)\n",
        "  F = np.matmul(X,A_l) + 1/m * np.matmul(np.matmul(np.ones((m,m)),X),B_l) + np.matmul(np.ones((m,1)),c_l.transpose())\n",
        "  return F\n"
      ],
      "metadata": {
        "id": "JZbfWBP-BeoS"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QZlfg5fWGjYc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}